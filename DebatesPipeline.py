import logging
import sys
import os
import asyncio
from typing import List, Iterator, Callable, Any, Dict
from pydantic import BaseModel
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores.pgvector import PGVector
import httpx
from PIL import Image
import io
import fitz  # PyMuPDF for PDF
import docx2txt
import base64
import mimetypes

logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))


class Pipeline:
    class Valves(BaseModel):
        MODEL_ID: str = "gpt-4o"
        TEMPERATURE: float = 0.5
        MAX_TOKENS: int = 1500
        OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")
        SEARCH_API_URL: str = os.getenv("SEARCH_API_URL", "http://localhost:8008/check_and_search")

    def __init__(self):
        self.name = "Debate Pipeline"
        self.valves = self.Valves()

    async def on_startup(self):
        logging.info("Pipeline is warming up...")

    async def on_shutdown(self):
        logging.info("Pipeline is shutting down...")

    async def call_search_api(self, prompt: str, pipeline: str = "DebatePipeline") -> Dict[str, Any]:
        try:
            async with httpx.AsyncClient(timeout=30) as client:
                response = await client.post(
                    self.valves.SEARCH_API_URL,
                    json={"prompt": prompt, "pipeline": pipeline}
                )
                response.raise_for_status()
                return response.json()
        except Exception as e:
            logging.error(f"Search API error: {e}")
            return {"search_required": False, "context": "", "citations": []}

    async def inlet(self, body: dict, user: dict) -> dict:
        import json

        logging.info(f"üì• Received inlet body:\n{json.dumps(body, indent=2, ensure_ascii=False)}")
        files = body.get("files", [])
        extracted_texts = []

        for file in files:
            try:
                content_url = file["url"] + "/content"
                async with httpx.AsyncClient(timeout=30) as client:
                    response = await client.get(content_url)
                    response.raise_for_status()
                    content = response.content

                mime_type = file.get("mime_type") or mimetypes.guess_type(file.get("name", ""))[0]

                if mime_type == "application/pdf":
                    doc = fitz.open(stream=content, filetype="pdf")
                    text = "\n".join([page.get_text() for page in doc])
                    extracted_texts.append(text)
                    doc.close()

                elif mime_type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
                    with open("temp.docx", "wb") as f:
                        f.write(content)
                    text = docx2txt.process("temp.docx")
                    os.remove("temp.docx")
                    extracted_texts.append(text)

                elif mime_type and mime_type.startswith("image/"):
                    image = Image.open(io.BytesIO(content))
                    from openai import OpenAI
                    client = OpenAI(api_key=self.valves.OPENAI_API_KEY)
                    base64_image = base64.b64encode(content).decode("utf-8")
                    ocr_response = client.chat.completions.create(
                        model=self.valves.MODEL_ID,
                        messages=[
                            {"role": "user", "content": [
                                {"type": "text", "text": "–†–∞—Å–ø–æ–∑–Ω–∞–π —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."},
                                {"type": "image_url", "image_url": {"url": f"data:{mime_type};base64,{base64_image}"}}
                            ]}
                        ]
                    )
                    image_text = ocr_response.choices[0].message.content.strip()
                    extracted_texts.append(image_text)
            except Exception as e:
                logging.error(f"Error processing file {file.get('name', 'unknown')}: {e}")
                continue

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        body["file_text"] = "\n".join(extracted_texts)

        # ‚úÖ –û–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è OpenWebUI
        if "messages" not in body or not isinstance(body["messages"], list):
            raise ValueError("Field 'messages' is required and must be a list.")
        if "model" not in body or not isinstance(body["model"], str):
            raise ValueError("Field 'model' is required and must be a string.")

        logging.info("‚úÖ inlet completed successfully.")
        return body

    def pipe(self, user_message: str, model_id: str, messages: List[dict], body: dict) -> Iterator[str]:
        """Main pipeline function with proper error handling and streaming"""
        try:
            # Extract file text if available
            file_text = body.get("file_text", "")
            if file_text:
                user_message += f"\n\n–¢–µ–∫—Å—Ç –∏–∑ –ø—Ä–∏–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:\n{file_text}"
            
            # –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á—ë–Ω –±–ª–æ–∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
            legal_context = ""
            
            # Check if this is a DebatePipeline request
            pipeline_type = body.get("pipeline", "DebatePipeline")
            
            if pipeline_type == "DebatePipeline":
                # Combined deep analysis + table format for DebatePipeline
                system_message = f"""
**–†–æ–ª—å**: –í—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–µ–±–∞—Ç–æ–≤, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –≥–ª—É–±–æ–∫–æ–º –∏ –±–µ—Å–ø—Ä–∏—Å—Ç—Ä–∞—Å—Ç–Ω–æ–º —Ä–∞–∑–±–æ—Ä–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –∞–∫—Ç–æ–≤ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞.

**–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤**:
{legal_context}

**–¶–µ–ª—å –∞–Ω–∞–ª–∏–∑–∞**:
1. –ü—Ä–æ–≤–µ—Å—Ç–∏ –≤—Å–µ—Å—Ç–æ—Ä–æ–Ω–Ω—é—é —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∞—Ä–≥—É–º–µ–Ω—Ç–∞
2. –û—Ü–µ–Ω–∏—Ç—å –ª–æ–≥–∏—á–µ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
3. –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–≤–µ –ª–∏–Ω–∏–∏ –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏–π: –≤—ã—Å—Ç—É–ø–∞—é—â–∏–π –∏ –æ–ø–ø–æ–Ω–µ–Ω—Ç
4. –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã, –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–ª—è –¥–µ–±–∞—Ç–æ–≤

**–°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–ê–Ø):**

### 1. –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–ø–∏—Å–∫–∞
- –ü–æ–ª–Ω—ã–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–±–æ—Ä –∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç–∞
- –í—ã—è–≤–ª–µ–Ω–∏–µ —Å–∏–ª—å–Ω—ã—Ö –∏ —Å–ª–∞–±—ã—Ö —Å—Ç–æ—Ä–æ–Ω —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π
- –£–∫–∞–∑–∞–Ω–∏–µ –Ω–µ—è–≤–Ω—ã—Ö –¥–æ–ø—É—â–µ–Ω–∏–π –∏ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π
- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∑–∏—Å–æ–≤ –ø–æ —É—Ä–æ–≤–Ω—é —É–±–µ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### 2. –°—Ü–µ–Ω–∞—Ä–∏–π –¥–µ–±–∞—Ç–æ–≤
- –í—ã–¥–µ–ª–µ–Ω–∏–µ –¥–≤—É—Ö —Å—Ç–æ—Ä–æ–Ω: –≤—ã—Å—Ç—É–ø–∞—é—â–∏–π (–∏–Ω–∏—Ü–∏–∞—Ç–æ—Ä) –∏ —Å–ª—É—à–∞—é—â–∏–π (–æ–ø–ø–æ–Ω–µ–Ω—Ç)
- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã:
  - –í–æ–ø—Ä–æ—Å—ã, —É—Å–∏–ª–∏–≤–∞—é—â–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ü–∏—é –≤—ã—Å—Ç—É–ø–∞—é—â–µ–≥–æ
  - –í–æ–ø—Ä–æ—Å—ã, —Ä–∞—Å–∫—Ä—ã–≤–∞—é—â–∏–µ —É—è–∑–≤–∏–º–æ—Å—Ç–∏ (–æ—Ç –æ–ø–ø–æ–Ω–µ–Ω—Ç–∞)
- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–º–µ—Ä–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ —ç—Ç–∏ –≤–æ–ø—Ä–æ—Å—ã
- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ª–∏–Ω–∏–π –∑–∞—â–∏—Ç—ã –∏ –∞—Ç–∞–∫–∏

### 3. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
- –ú–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã –¥–ª—è —É—Å–∏–ª–µ–Ω–∏—è —Ä–∏—Ç–æ—Ä–∏–∫–∏ –≤—ã—Å—Ç—É–ø–∞—é—â–µ–≥–æ
- –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–µ–∞–≥–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–º–µ—á–∞–Ω–∏—è
- –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫ –∏ –ø–æ–∑–∏—Ü–∏–∏

### 4. –ò–¢–û–ì–û–í–ê–Ø –¢–ê–ë–õ–ò–¶–ê –ê–†–ì–£–ú–ï–ù–¢–û–í (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û!)

–í –∫–æ–Ω—Ü–µ –∞–Ω–∞–ª–∏–∑–∞ –í–°–ï–ì–î–ê –ø—Ä–∏–≤–æ–¥–∏ —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –æ—Å–Ω–æ–≤–Ω—ã—Ö –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤:

| –ê—Ä–≥—É–º–µ–Ω—Ç | –ò—Å—Ç–æ—á–Ω–∏–∫ | –ü–æ–¥–¥–µ—Ä–∂–∫–∞ | –í–æ–∑—Ä–∞–∂–µ–Ω–∏—è |
|----------|----------|-----------|-------------|
| [–ö–ª—é—á–µ–≤–æ–π –∞—Ä–≥—É–º–µ–Ω—Ç] | [–ò—Å—Ç–æ—á–Ω–∏–∫/–¥–æ–∫—É–º–µ–Ω—Ç] | [–û—Å–Ω–æ–≤–Ω—ã–µ –¥–æ–≤–æ–¥—ã –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É] | [–ì–ª–∞–≤–Ω—ã–µ –∫–æ–Ω—Ç—Ä–∞—Ä–≥—É–º–µ–Ω—Ç—ã] |
| ... | ... | ... | ... |

**–ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã:**
- –í–∫–ª—é—á–∏—Ç—å 5-7 –∫–ª—é—á–µ–≤—ã—Ö –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
- –£–∫–∞–∑—ã–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–∑–∞–∫–æ–Ω—ã, –ù–ü–ê, —Å—Ç–∞—Ç—å–∏)
- –ö—Ä–∞—Ç–∫–æ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å —Å—É—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π
- –¢–∞–±–ª–∏—Ü–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∏—Ç–æ–≥–æ–≤—ã–º —Ä–µ–∑—é–º–µ –≤—Å–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞

–ë–ï–ó –ü–û–õ–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê –ò –ò–¢–û–ì–û–í–û–ô –¢–ê–ë–õ–ò–¶–´ –û–¢–í–ï–¢ –ù–ï–î–û–ü–£–°–¢–ò–ú!
"""
            else:
                # Original system message for other pipelines
                system_message = f"""
**–†–æ–ª—å**: –í—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–µ–±–∞—Ç–æ–≤, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –≥–ª—É–±–æ–∫–æ–º –∏ –±–µ—Å–ø—Ä–∏—Å—Ç—Ä–∞—Å—Ç–Ω–æ–º —Ä–∞–∑–±–æ—Ä–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –∞–∫—Ç–æ–≤ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞.

**–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤**:
{legal_context}

**–¶–µ–ª—å –∞–Ω–∞–ª–∏–∑–∞**:
1. –ü—Ä–æ–≤–µ—Å—Ç–∏ –≤—Å–µ—Å—Ç–æ—Ä–æ–Ω–Ω—é—é —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∞—Ä–≥—É–º–µ–Ω—Ç–∞
2. –û—Ü–µ–Ω–∏—Ç—å –ª–æ–≥–∏—á–µ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
3. –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–≤–µ –ª–∏–Ω–∏–∏ –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏–π: –≤—ã—Å—Ç—É–ø–∞—é—â–∏–π –∏ –æ–ø–ø–æ–Ω–µ–Ω—Ç
4. –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã, –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–ª—è –¥–µ–±–∞—Ç–æ–≤

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∞–Ω–∞–ª–∏–∑—É**:

#### 1. –†–∞–∑–¥–µ–ª "–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–ø–∏—Å–∫–∞"
- –ü–æ–ª–Ω—ã–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–±–æ—Ä –∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç–∞
- –í—ã—è–≤–ª–µ–Ω–∏–µ —Å–∏–ª—å–Ω—ã—Ö –∏ —Å–ª–∞–±—ã—Ö —Å—Ç–æ—Ä–æ–Ω —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π
- –£–∫–∞–∑–∞–Ω–∏–µ –Ω–µ—è–≤–Ω—ã—Ö –¥–æ–ø—É—â–µ–Ω–∏–π –∏ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π
- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∑–∏—Å–æ–≤ –ø–æ —É—Ä–æ–≤–Ω—é —É–±–µ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

#### 2. –†–∞–∑–¥–µ–ª "–°—Ü–µ–Ω–∞—Ä–∏–π –¥–µ–±–∞—Ç–æ–≤"
- –í—ã–¥–µ–ª–µ–Ω–∏–µ –¥–≤—É—Ö —Å—Ç–æ—Ä–æ–Ω: –≤—ã—Å—Ç—É–ø–∞—é—â–∏–π (–∏–Ω–∏—Ü–∏–∞—Ç–æ—Ä) –∏ —Å–ª—É—à–∞—é—â–∏–π (–æ–ø–ø–æ–Ω–µ–Ω—Ç)
- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã:
  - –í–æ–ø—Ä–æ—Å—ã, —É—Å–∏–ª–∏–≤–∞—é—â–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ü–∏—é –≤—ã—Å—Ç—É–ø–∞—é—â–µ–≥–æ
  - –í–æ–ø—Ä–æ—Å—ã, —Ä–∞—Å–∫—Ä—ã–≤–∞—é—â–∏–µ —É—è–∑–≤–∏–º–æ—Å—Ç–∏ (–æ—Ç –æ–ø–ø–æ–Ω–µ–Ω—Ç–∞)
- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–º–µ—Ä–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ —ç—Ç–∏ –≤–æ–ø—Ä–æ—Å—ã
- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ª–∏–Ω–∏–π –∑–∞—â–∏—Ç—ã –∏ –∞—Ç–∞–∫–∏

#### 3. –†–∞–∑–¥–µ–ª "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é"
- –ú–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã –¥–ª—è —É—Å–∏–ª–µ–Ω–∏—è —Ä–∏—Ç–æ—Ä–∏–∫–∏ –≤—ã—Å—Ç—É–ø–∞—é—â–µ–≥–æ
- –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–µ–∞–≥–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–º–µ—á–∞–Ω–∏—è
- –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫ –∏ –ø–æ–∑–∏—Ü–∏–∏
"""

            # Get search results
            search_result = asyncio.run(self.call_search_api(user_message, pipeline_type))
            if search_result["search_required"] and search_result["context"]:
                user_message += "\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:\n" + search_result["context"]
            
            # Initialize model
            model = ChatOpenAI(
                api_key=self.valves.OPENAI_API_KEY,
                model=self.valves.MODEL_ID,
                temperature=self.valves.TEMPERATURE,
                streaming=True,
                max_tokens=self.valves.MAX_TOKENS
            )
            
            # Create prompt
            prompt = ChatPromptTemplate.from_messages([
                SystemMessagePromptTemplate.from_template(system_message),
                HumanMessagePromptTemplate.from_template("{user_input}")
            ])
            
            formatted_messages = prompt.format_messages(user_input=user_message)
            
            # Handle streaming vs non-streaming
            if body.get("stream", True):
                # Streaming response
                try:
                    for chunk in model.stream(formatted_messages):
                        content = getattr(chunk, "content", None)
                        if content:
                            logging.debug(f"Model chunk: {content}")
                            yield content
                    
                    # Add citations if available
                    if search_result["search_required"] and search_result["citations"]:
                        yield "\n\n### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:"
                        for i, link in enumerate(search_result["citations"], 1):
                            yield f"\n[{i}] {link}"
                    
                    # Ensure stream is properly closed
                    yield ""
                    
                except Exception as e:
                    logging.error(f"Streaming error: {e}")
                    yield f"\n\n‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}"
            else:
                # Non-streaming response
                try:
                    full_response = ""
                    for chunk in model.stream(formatted_messages):
                        content = getattr(chunk, "content", None)
                        if content:
                            full_response += content
                    
                    # Add citations if available
                    if search_result["search_required"] and search_result["citations"]:
                        full_response += "\n\n### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:"
                        for i, link in enumerate(search_result["citations"], 1):
                            full_response += f"\n[{i}] {link}"
                    
                    yield full_response
                    
                except Exception as e:
                    logging.error(f"Non-streaming error: {e}")
                    yield f"‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}"
                    
        except Exception as e:
            logging.error(f"Pipeline error: {e}", exc_info=True)
            yield f"‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ pipeline: {str(e)}"
