import logging
import sys
import os
import asyncio
from typing import List, Iterator, Callable
from pydantic import BaseModel
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores.pgvector import PGVector
from typing import List, Iterator, Callable, Any, Dict
from pydantic import BaseModel
import httpx
from PIL import Image
import io
import fitz  # PyMuPDF for PDF
import docx2txt
import base64
import mimetypes

logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))


class Pipeline:
    class Valves(BaseModel):
        MODEL_ID: str = "gpt-4o"
        TEMPERATURE: float = 0.5
        MAX_TOKENS: int = 1500
        OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")
        SEARCH_API_URL: str = os.getenv("SEARCH_API_URL", "http://localhost:8008/check_and_search")

    def __init__(self):
        self.name = "Debate Pipeline"
        self.valves = self.Valves()

    async def on_startup(self):
        logging.info("Pipeline is warming up...")

    async def on_shutdown(self):
        logging.info("Pipeline is shutting down...")

    async def make_request_with_retry(self, fn: Callable[[], Iterator[str]], retries=3) -> Iterator[str]:
        for attempt in range(retries):
            try:
                return fn()
            except Exception as e:
                logging.error(f"Attempt {attempt + 1} failed: {e}")
                if attempt + 1 == retries:
                    raise
                await asyncio.sleep(2 ** attempt)

    async def call_search_api(self, prompt: str) -> Dict[str, Any]:
        try:
            async with httpx.AsyncClient(timeout=20) as client:
                response = await client.post(
                    self.valves.SEARCH_API_URL,
                    json={"prompt": prompt, "pipeline": "DebatePipeline"}
                )
                response.raise_for_status()
                return response.json()
        except Exception as e:
            logging.error(f"Search API error: {e}")
            return {"search_required": False, "context": "", "citations": []}

    async def call_deep_extract_api(self, prompt: str, citations: List[str]) -> str:
        try:
            async with httpx.AsyncClient(timeout=60) as client:
                response = await client.post(
                    self.valves.SEARCH_API_URL.replace("/check_and_search", "/deep_extract_and_analyze"),
                    json={"prompt": prompt, "citations": citations, "pipeline": "DebatePipeline"}
                )
                response.raise_for_status()
                return response.json().get("legal_context", "")
        except Exception as e:
            logging.error(f"Deep extract API error: {e}")
            return ""


    async def inlet(self, body: dict, user: dict) -> dict:
        import json
        logging.info("üì• Inlet body:\n" + json.dumps(body, indent=2, ensure_ascii=False))
    
        extracted = []
        for f in body.get("files", []):
            url = f.get("url", "")
            content = None
    
            if url.startswith("http://") or url.startswith("https://"):
                content_url = url + "/content"
                async with httpx.AsyncClient(timeout=30) as c:
                    resp = await c.get(content_url)
                    resp.raise_for_status()
                    content = resp.content
            elif url.startswith("data:"):
                # –ü—Ä–∏–º–µ—Ä: data:application/vnd.openxmlformats-officedocument.wordprocessingml.document;base64,...
                header, b64data = url.split(",", 1)
                content = base64.b64decode(b64data)
            else:
                logging.warning(f"‚ö†Ô∏è Unsupported or missing URL scheme: {url}")
                continue
    
            mime = f.get("mime_type") or mimetypes.guess_type(f.get("name", ""))[0]
            if mime == "application/pdf":
                doc = fitz.open(stream=content, filetype="pdf")
                extracted.append("\n".join(p.get_text() for p in doc))
            elif mime == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
                with open("_tmp.docx", "wb") as tmp:
                    tmp.write(content)
                extracted.append(docx2txt.process("_tmp.docx"))
                os.remove("_tmp.docx")
            elif mime and mime.startswith("image/"):
                b64 = base64.b64encode(content).decode()
                res = self.client.chat.completions.create(
                    model=self.valves.MODEL_ID,
                    messages=[{"role": "user", "content": [
                        {"type": "text", "text": "–†–∞—Å–ø–æ–∑–Ω–∞–π —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."},
                        {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{b64}"}}
                    ]}]
                )
                extracted.append(res.choices[0].message.content.strip())
    
        body["file_text"] = "\n".join(extracted)
        return body


    def pipe(self, user_message: str, model_id: str, messages: List[dict], body: dict) -> Iterator[str]:
        file_text = body.get("file_text", "")
        if file_text:
            user_message += f"\n\n–¢–µ–∫—Å—Ç –∏–∑ –ø—Ä–∏–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:\n{file_text}"
        # –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á—ë–Ω –±–ª–æ–∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
        legal_context = ""

        # System message with injected legal context
        system_message = f"""
**–†–æ–ª—å**: –í—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–µ–±–∞—Ç–æ–≤, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –≥–ª—É–±–æ–∫–æ–º –∏ –±–µ—Å–ø—Ä–∏—Å—Ç—Ä–∞—Å—Ç–Ω–æ–º —Ä–∞–∑–±–æ—Ä–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –∞–∫—Ç–æ–≤ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞.

**–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤**:
{legal_context}

**–¶–µ–ª—å –∞–Ω–∞–ª–∏–∑–∞**:
1. –ü—Ä–æ–≤–µ—Å—Ç–∏ –≤—Å–µ—Å—Ç–æ—Ä–æ–Ω–Ω—é—é —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∞—Ä–≥—É–º–µ–Ω—Ç–∞
2. –û—Ü–µ–Ω–∏—Ç—å –ª–æ–≥–∏—á–µ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
3. –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–≤–µ –ª–∏–Ω–∏–∏ –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏–π: –≤—ã—Å—Ç—É–ø–∞—é—â–∏–π –∏ –æ–ø–ø–æ–Ω–µ–Ω—Ç
4. –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã, –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–ª—è –¥–µ–±–∞—Ç–æ–≤

**–°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–ê–Ø):**

### 1. –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–ø–∏—Å–∫–∞
- –ü–æ–ª–Ω—ã–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–±–æ—Ä –∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç–∞
- –í—ã—è–≤–ª–µ–Ω–∏–µ —Å–∏–ª—å–Ω—ã—Ö –∏ —Å–ª–∞–±—ã—Ö —Å—Ç–æ—Ä–æ–Ω —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π
- –£–∫–∞–∑–∞–Ω–∏–µ –Ω–µ—è–≤–Ω—ã—Ö –¥–æ–ø—É—â–µ–Ω–∏–π –∏ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π
- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∑–∏—Å–æ–≤ –ø–æ —É—Ä–æ–≤–Ω—é —É–±–µ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### 2. –°—Ü–µ–Ω–∞—Ä–∏–π –¥–µ–±–∞—Ç–æ–≤
- –í—ã–¥–µ–ª–µ–Ω–∏–µ –¥–≤—É—Ö —Å—Ç–æ—Ä–æ–Ω: –≤—ã—Å—Ç—É–ø–∞—é—â–∏–π (–∏–Ω–∏—Ü–∏–∞—Ç–æ—Ä) –∏ —Å–ª—É—à–∞—é—â–∏–π (–æ–ø–ø–æ–Ω–µ–Ω—Ç)
- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã:
  - –í–æ–ø—Ä–æ—Å—ã, —É—Å–∏–ª–∏–≤–∞—é—â–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ü–∏—é –≤—ã—Å—Ç—É–ø–∞—é—â–µ–≥–æ
  - –í–æ–ø—Ä–æ—Å—ã, —Ä–∞—Å–∫—Ä—ã–≤–∞—é—â–∏–µ —É—è–∑–≤–∏–º–æ—Å—Ç–∏ (–æ—Ç –æ–ø–ø–æ–Ω–µ–Ω—Ç–∞)
- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–º–µ—Ä–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ —ç—Ç–∏ –≤–æ–ø—Ä–æ—Å—ã
- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ª–∏–Ω–∏–π –∑–∞—â–∏—Ç—ã –∏ –∞—Ç–∞–∫–∏

### 3. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
- –ú–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã –¥–ª—è —É—Å–∏–ª–µ–Ω–∏—è —Ä–∏—Ç–æ—Ä–∏–∫–∏ –≤—ã—Å—Ç—É–ø–∞—é—â–µ–≥–æ
- –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–µ–∞–≥–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–º–µ—á–∞–Ω–∏—è
- –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫ –∏ –ø–æ–∑–∏—Ü–∏–∏

### 4. –ò–¢–û–ì–û–í–ê–Ø –¢–ê–ë–õ–ò–¶–ê –ê–†–ì–£–ú–ï–ù–¢–û–í (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û!)

–í –∫–æ–Ω—Ü–µ –∞–Ω–∞–ª–∏–∑–∞ –í–°–ï–ì–î–ê –ø—Ä–∏–≤–æ–¥–∏ —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –æ—Å–Ω–æ–≤–Ω—ã—Ö –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤:

| –ê—Ä–≥—É–º–µ–Ω—Ç | –ò—Å—Ç–æ—á–Ω–∏–∫ | –ü–æ–¥–¥–µ—Ä–∂–∫–∞ | –í–æ–∑—Ä–∞–∂–µ–Ω–∏—è |
|----------|----------|-----------|-------------|
| [–ö–ª—é—á–µ–≤–æ–π –∞—Ä–≥—É–º–µ–Ω—Ç] | [–ò—Å—Ç–æ—á–Ω–∏–∫/–¥–æ–∫—É–º–µ–Ω—Ç] | [–û—Å–Ω–æ–≤–Ω—ã–µ –¥–æ–≤–æ–¥—ã –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É] | [–ì–ª–∞–≤–Ω—ã–µ –∫–æ–Ω—Ç—Ä–∞—Ä–≥—É–º–µ–Ω—Ç—ã] |
| ... | ... | ... | ... |

**–ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã:**
- –í—ã–¥–µ–ª–∏—Ç—å –≤ –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ö –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —É–ø–æ–º—è–Ω—É—Ç—ã–µ –Ω–æ—Ä–º—ã: —Å—Ç–∞—Ç—å–∏, –ø—É–Ω–∫—Ç—ã, –∑–∞–∫–æ–Ω—ã, –∫–æ–¥–µ–∫—Å—ã
- –£–∫–∞–∑–∞—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –Ω–æ–º–µ—Ä —Å—Ç–∞—Ç—å–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´—Å—Ç–∞—Ç—å—è 9 –ó–∞–∫–æ–Ω–∞ ‚Äû–û –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö‚Äú¬ª)
- –û—Ç—Ä–∞–∂–∞—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ –ø—Ä–æ—Å—Ç–æ –∫–∞–∫ "–ó–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç", –∞ –∫–∞–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∑–∞–∫–æ–Ω/–∫–æ–¥–µ–∫—Å
- –û–±–æ—Å–Ω–æ–≤—ã–≤–∞—Ç—å –ø–æ–∑–∏—Ü–∏—é —Å—Ç–æ—Ä–æ–Ω —Å –æ–ø–æ—Ä–æ–π –Ω–∞ —ç—Ç–∏ –Ω–æ—Ä–º—ã

–ë–ï–ó –ü–û–õ–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê –ò –ò–¢–û–ì–û–í–û–ô –¢–ê–ë–õ–ò–¶–´ –û–¢–í–ï–¢ –ù–ï–î–û–ü–£–°–¢–ò–ú!
"""

        search_result = asyncio.run(self.call_search_api(user_message))
        if search_result["search_required"] and search_result["context"]:
            user_message += "\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:\n" + search_result["context"]
        deep_legal_context = ""
        if search_result["search_required"] and search_result["citations"]:
            deep_legal_context = asyncio.run(self.call_deep_extract_api(user_message, search_result["citations"]))
            if deep_legal_context:
                user_message += (
                    "\n\nüìò –ü–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω—ã–µ –Ω–æ—Ä–º—ã –∑–∞–∫–æ–Ω–∞ (–∏–∑ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤):\n"
                    f"{deep_legal_context}\n"
                    "\n‚ùóÔ∏è–£–∫–∞–∑—ã–≤–∞–π –¢–û–õ–¨–ö–û —Å—Ç–∞—Ç—å–∏, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ —ç—Ç–æ–º —Å–ø–∏—Å–∫–µ. –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π!"
                )
        model = ChatOpenAI(
            api_key=self.valves.OPENAI_API_KEY,
            model=self.valves.MODEL_ID,
            temperature=self.valves.TEMPERATURE,
            streaming=True
        )
    
        prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(system_message),
            HumanMessagePromptTemplate.from_template("{user_input}")
        ])
    
        formatted_messages = prompt.format_messages(user_input=user_message)
    
        def stream_model() -> Iterator[str]:
            for chunk in model.stream(formatted_messages):
                content = getattr(chunk, "content", None)
                if content:
                    logging.debug(f"Model chunk: {content}")
                    yield content
            if search_result["search_required"] and search_result["citations"]:
                yield "\n\n### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:"
                for i, link in enumerate(search_result["citations"], 1):
                    yield f"\n[{i}] {link}"
    
        if body.get("stream", True):
            return asyncio.run(self.make_request_with_retry(stream_model))
        else:
            full_response = "".join(asyncio.run(self.make_request_with_retry(stream_model)))
            return full_response
