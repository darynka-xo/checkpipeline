import logging
import sys
import os
import asyncio
import requests
from bs4 import BeautifulSoup
from typing import List, Iterator, Sequence, Callable
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.tools import tool, BaseTool
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_core.messages import SystemMessage, HumanMessage

logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))


class WebSearchInput(BaseModel):
    query: str = Field(description="Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚Ğµ")


@tool("search_kz_web", args_schema=WebSearchInput, return_direct=False)
def search_kz_web(query: str) -> str:
    """ĞŸĞ¾Ğ¸ÑĞº, Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³ Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğ³Ğ¾ ĞºĞ°Ğ·Ğ°Ñ…ÑÑ‚Ğ°Ğ½ÑĞºĞ¸Ñ… Ğ¾Ñ„Ğ¸Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²."""
    try:
        trusted_sites = [
            "site:senate.parlam.kz", "site:akorda.kz", "site:primeminister.kz",
            "site:otyrys.prk.kz", "site:senate-zan.prk.kz",
            "site:lib.prk.kz", "site:online.zakon.kz", "site:adilet.zan.kz",
            "site:legalacts.egov.kz", "site:egov.kz", "site:eotinish.kz"
        ]
        query_with_sites = f"{query} " + " OR ".join(trusted_sites)
        url = f"https://www.google.com/search?q={requests.utils.quote(query_with_sites)}&hl=ru"
        headers = {"User-Agent": "Mozilla/5.0"}
        html = requests.get(url, headers=headers, timeout=10).text
        soup = BeautifulSoup(html, "html.parser")

        results = []
        for g in soup.select(".tF2Cxc")[:3]:
            title = g.select_one("h3")
            snippet = g.select_one(".VwiC3b")
            link = g.select_one("a")
            if title and snippet and link:
                full_text = extract_text_from_url(link['href'])
                summary = analyze_external_text(full_text, link['href'])
                results.append(
                    f"ğŸ”— {title.text}\n{snippet.text}\n{link['href']}\n---\n{summary.strip()}\n"
                )


        return "Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²:\n\n" + "\n".join(results) if results else "ĞĞ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ½Ğ° Ğ¾Ñ„Ğ¸Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ°Ñ…."
    except Exception as e:
        return f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ¸ÑĞºĞ°: {str(e)}"


def extract_text_from_url(url: str) -> str:
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, "html.parser")
        paragraphs = soup.find_all("p")
        text = "\n".join(p.get_text(strip=True) for p in paragraphs)
        return text.strip() if text else "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ."
    except Exception as e:
        return f"[ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ°: {str(e)}]"


def analyze_external_text(text: str, source_url: str) -> str:
    try:
        if not text or "ĞÑˆĞ¸Ğ±ĞºĞ°" in text:
            return text

        model = ChatOpenAI(
            api_key=os.getenv("OPENAI_API_KEY", ""),
            model="gpt-4o",
            temperature=0.5
        )

        messages = [
            SystemMessage(content="Ğ’Ñ‹ â€” ÑĞºÑĞ¿ĞµÑ€Ñ‚ Ğ¿Ğ¾ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¸ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞµ. ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ğ¸ ÑĞ´ĞµĞ»Ğ°Ğ¹Ñ‚Ğµ 2â€“3 ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ°, ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ñ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¼ Ğ¿Ğ¾ÑÑĞ½ĞµĞ½Ğ¸ĞµĞ¼. Ğ’ ĞºĞ¾Ğ½Ñ†Ğµ Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ: [Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº: URL]."),
            HumanMessage(content=text[:4000])
        ]

        result = model.invoke(messages)
        return f"{result.content}\n[Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº: {source_url}]"
    except Exception as e:
        return f"[ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°: {str(e)}]"


class Pipeline:
    class Valves(BaseModel):
        MODEL_ID: str = "gpt-4o"
        TEMPERATURE: float = 0.7
        MAX_TOKENS: int = 1500
        OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")

    def __init__(self):
        self.name = "Negotiation Strategy Predictor with Search"
        self.valves = self.Valves()

    async def on_startup(self):
        logging.info("Pipeline is warming up...")

    async def on_shutdown(self):
        logging.info("Pipeline is shutting down...")

    async def make_request_with_retry(self, fn: Callable[[], Iterator[str]], retries=3) -> Iterator[str]:
        for attempt in range(retries):
            try:
                return fn()
            except Exception as e:
                logging.error(f"Attempt {attempt + 1} failed: {e}")
                if attempt + 1 == retries:
                    raise
                await asyncio.sleep(2 ** attempt)

    def pipe(
        self, user_message: str, model_id: str, messages: List[dict], body: dict
    ) -> Iterator[str]:

        system_message = """
**Ğ Ğ¾Ğ»ÑŒ:** Ğ’Ñ‹ â€” ÑĞºÑĞ¿ĞµÑ€Ñ‚ Ğ¿Ğ¾ Ğ¿ĞµÑ€ĞµĞ³Ğ¾Ğ²Ğ¾Ñ€Ğ°Ğ¼ Ğ¸ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼Ñƒ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ. Ğ’Ğ°ÑˆĞ° ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ â€” Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¸ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ÑÑ‚Ğ¸ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ Ğ¿ĞµÑ€ĞµĞ³Ğ¾Ğ²Ğ¾Ñ€Ğ¾Ğ² Ğ¸ ĞºĞ¾Ğ¼Ğ¼ÑƒĞ½Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹. Ğ’Ñ‹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚Ğµ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ² Ñ€Ğ°Ğ¼ĞºĞ°Ñ… Ğ¿ĞµÑ€ĞµĞ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸.

**ĞĞ±Ğ»Ğ°ÑÑ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸:** Ğ’Ñ‹ Ğ½Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°ĞµÑ‚Ğµ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹, Ğ½Ğµ ÑĞ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ¼ Ğ¿ĞµÑ€ĞµĞ³Ğ¾Ğ²Ğ¾Ñ€Ğ¾Ğ², ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚Ğ¾Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ¾Ğ², ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹ ÑƒĞ±ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¸Ğ»Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ĞºĞ¾Ğ¼Ğ¿Ñ€Ğ¾Ğ¼Ğ¸ÑÑĞ½Ñ‹Ñ… Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹. Ğ’ ÑĞ»ÑƒÑ‡Ğ°Ğµ Ğ½ĞµÑ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğ²Ñ‹ Ğ¼ÑĞ³ĞºĞ¾ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ÑĞµÑ‚Ğµ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚Ğµ ÑÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿ĞµÑ€ĞµĞ³Ğ¾Ğ²Ğ¾Ñ€Ğ½ÑƒÑ ÑĞ¸Ñ‚ÑƒĞ°Ñ†Ğ¸Ñ, Ğ² ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¹ Ğ²Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‡ÑŒ.

**Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸:**
- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ñ„Ğ¸Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸ (gov.kz, adilet.zan.kz, egov.kz Ğ¸ Ñ‚.Ğ´.), ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¸ÑĞºĞ°Ñ‚ÑŒ Ğ²Ğ½ĞµÑˆĞ½ÑÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ.
- ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ² Ğ¸ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ñ‹.

**Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°:**
### 1. Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¿Ñ€Ğ¾Ğ¼Ğ¸ÑÑĞ½Ñ‹Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ
### 2. ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸
### 3. Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸
"""

        model = ChatOpenAI(
            api_key=self.valves.OPENAI_API_KEY,
            model=self.valves.MODEL_ID,
            temperature=self.valves.TEMPERATURE,
            streaming=True
        )

        tools: Sequence[BaseTool] = [search_kz_web]

        prompt = ChatPromptTemplate.from_messages([
            ("system", system_message),
            MessagesPlaceholder("chat_history"),
            ("user", "{input}"),
            MessagesPlaceholder("agent_scratchpad")
        ])

        agent = create_tool_calling_agent(model, tools, prompt)
        agent_executor = AgentExecutor(
            agent=agent,
            tools=tools,
            verbose=True,
            handle_parsing_errors=True,
            streaming=True
        )

        def stream_agent() -> Iterator[str]:
            for chunk in agent_executor.stream({
                "input": user_message,
                "chat_history": messages
            }):
                output = chunk.get("output")
                if output:
                    logging.debug(f"Agent chunk: {output}")
                    yield output

        return asyncio.run(self.make_request_with_retry(stream_agent))
