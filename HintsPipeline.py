import logging
import sys
import os
import asyncio
import re
import httpx
import mimetypes
import base64
import io
from typing import List, Iterator, Callable, Any, Dict

from pydantic import BaseModel
from openai import OpenAI
from PIL import Image
import fitz
import docx2txt
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate

logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))

class Pipeline:
    class Valves(BaseModel):
        MODEL_ID: str = "gpt-4.1"
        TEMPERATURE: float = 0.5
        MAX_TOKENS: int = 1800
        OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")

    def __init__(self):
        self.name = "–õ–∏—Ç–ì–∏–¥"
        self.valves = self.Valves()
        self.client = OpenAI(api_key=self.valves.OPENAI_API_KEY)

    async def on_startup(self):
        logging.info("Hints pipeline warming up‚Ä¶")

    async def on_shutdown(self):
        logging.info("Hints pipeline shutting down‚Ä¶")

    async def make_request_with_retry(self, fn: Callable[[], Iterator[str]], retries=3) -> Iterator[str]:
        for attempt in range(retries):
            try:
                return fn()
            except Exception as e:
                logging.error(f"Attempt {attempt+1} failed: {e}")
                if attempt + 1 == retries:
                    raise
                await asyncio.sleep(2 ** attempt)

    async def web_search(self, query: str) -> List[Dict[str, str]]:
        try:
            response = self.client.responses.create(
                model="gpt-4.1",
                tools=[{"type": "web_search_preview"}],
                input=query
            )
            return [{
                "title": "OpenAI Web Search",
                "link": "https://www.google.com/search?q=" + query.replace(" ", "+"),
                "snippet": response.output_text
            }]
        except Exception as e:
            logging.warning(f"OpenAI web_search_preview error: {e}")
            return []

    async def inlet(self, body: dict, user: dict) -> dict:
        import json
        logging.info("üì• Inlet body:\n" + json.dumps(body, indent=2, ensure_ascii=False))

        extracted = []
        for f in body.get("files", []):
            url = f.get("url", "")
            content = None

            if url.startswith("http://") or url.startswith("https://"):
                content_url = url + "/content"
                async with httpx.AsyncClient(timeout=30) as c:
                    resp = await c.get(content_url)
                    resp.raise_for_status()
                    content = resp.content
            elif url.startswith("data:"):
                header, b64data = url.split(",", 1)
                content = base64.b64decode(b64data)
            else:
                logging.warning(f"‚ö†Ô∏è Unsupported or missing URL scheme: {url}")
                continue

            mime = f.get("mime_type") or mimetypes.guess_type(f.get("name", ""))[0]
            if mime == "application/pdf":
                doc = fitz.open(stream=content, filetype="pdf")
                extracted.append("\n".join(p.get_text() for p in doc))
            elif mime == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
                with open("_tmp.docx", "wb") as tmp:
                    tmp.write(content)
                extracted.append(docx2txt.process("_tmp.docx"))
                os.remove("_tmp.docx")
            elif mime and mime.startswith("image/"):
                b64 = base64.b64encode(content).decode()
                res = self.client.chat.completions.create(
                    model=self.valves.MODEL_ID,
                    messages=[{"role": "user", "content": [
                        {"type": "text", "text": "–†–∞—Å–ø–æ–∑–Ω–∞–π —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."},
                        {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{b64}"}}
                    ]}]
                )
                extracted.append(res.choices[0].message.content.strip())

        body["file_text"] = "\n".join(extracted)
        return body

    def pipe(self, user_message: str, model_id: str, messages: List[dict], body: dict) -> Iterator[str]:
        if body.get("file_text"):
            if not user_message.strip():
                user_message = body["file_text"]
            else:
                user_message += "\n\n–¢–µ–∫—Å—Ç –∏–∑ –ø—Ä–∏–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:\n" + body["file_text"]

        system_message = (
            "–í—ã ‚Äî –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∑–∞–∫–æ–Ω–æ—Ç–≤–æ—Ä—Ü–µ–≤ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø–æ–¥—Å–∫–∞–∑–æ–∫, –æ–±–∑–æ—Ä–æ–≤ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–º –æ–ø—ã—Ç–µ, –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö –∏ –ª—É—á—à–∏—Ö –ø—Ä–∞–∫—Ç–∏–∫–∞—Ö.\n"
            "–í–∞—à–∞ –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–µ –∏ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ø–æ —Ç–µ–º–µ –ø—Ä–æ–µ–∫—Ç–∞ –∑–∞–∫–æ–Ω–∞.\n"
            "**–¶–µ–ª—å:**\n"
            "1. –ü–æ–º–æ—á—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –Ω–∞–π—Ç–∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ç–µ–º–µ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω–æ–π –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã.\n"
            "2. –°–æ—Å—Ç–∞–≤–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –∏–ª–∏ –æ–±–∑–æ—Ä —Å —É—á—ë—Ç–æ–º –∫–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–æ–≥–æ –∏ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\n"
            "3. –ü—Ä–∏–≤–µ—Å—Ç–∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –∏–ª–∏ –Ω–∞—É—á–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –¥–æ—Å—Ç—É–ø–Ω—ã. \n"
            "**–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:\n**"
            "- –í–≤–µ–¥–µ–Ω–∏–µ –≤ —Ç–µ–º—É\n"
            "- –ö—Ä–∞—Ç–∫–∏–π –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–π –∏ –∫–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç\n"
            "- –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)\n"
            "- –ü—Ä–∞–∫—Ç–∏–∫–∏, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏–ª–∏ –ø–æ–¥—Å–∫–∞–∑–∫–∏\n"
            "–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —à–∞–≥–∏:\n"
            "1. –ù–∞–π—Ç–∏ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—É: —Å—Ç–∞—Ç—å–∏, –∫–Ω–∏–≥–∏, –¥–æ–∫–ª–∞–¥—ã, –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—Ç—á—ë—Ç—ã.\n"
            "2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ —É–∫–∞–∂–∏—Ç–µ: –Ω–∞–∑–≤–∞–Ω–∏–µ, –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ (–∞–Ω–Ω–æ—Ç–∞—Ü–∏—é), —Å—Å—ã–ª–∫—É.\n"
            "3. –†–∞–∑–¥–µ–ª–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ø–æ —Ç–∏–ø—É: –Ω–∞—É—á–Ω—ã–µ, –∞–Ω–∞–ª–∏—Ç–∏–∫–∞, –∫–Ω–∏–≥–∏ –∏ —Ç.–¥.\n"
            "4. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ markdown –∏–ª–∏ HTML.\n"
            "5. –î–æ–±–∞–≤—å—Ç–µ –∫—Ä–∞—Ç–∫—É—é —Å–ø—Ä–∞–≤–∫—É —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –Ω–∞–π–¥–µ–Ω–Ω–æ–π –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã."
        )

        async def _generate() -> str:
            try:
                results = await self.web_search(user_message)
                context = "\n".join([f"{r['title']}\n{r['link']}\n{r['snippet']}" for r in results])
                prompt = f"{system_message}\n\n–ó–∞–ø—Ä–æ—Å:\n{user_message}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞:\n{context}"
                response = self.client.responses.create(
                    model="gpt-4.1",
                    tools=[{"type": "web_search_preview"}],
                    input=prompt
                )
                return response.output_text
            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
                return "‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑."

        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        return loop.run_until_complete(_generate())
