import logging
import sys
import os
import asyncio
import re
import httpx
import mimetypes
import base64
import io
from typing import List, Iterator, Callable, Dict

from pydantic import BaseModel
from PIL import Image
import fitz  # PyMuPDF
import docx2txt
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate

logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))

TRUSTED_DOMAINS = [
    "open.zakon.kz", "legalacts.egov.kz", "adilet.zan.kz",
    "online.zakon.kz", "egov.kz", "eotinish.kz", "tengrinews.kz",
    "kursiv.media", "inbusiness.kz", "kapital.kz"
]

def _is_trusted(url: str) -> bool:
    return any(d in url for d in TRUSTED_DOMAINS)

def clean_html(text: str) -> str:
    text = re.sub(r"<[^>]+>", " ", text)
    text = re.sub(r"\s+", " ", text)
    return text.strip()

async def web_search(query: str) -> List[Dict[str, str]]:
    try:
        from openai import OpenAI
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        response = client.responses.create(
            model="gpt-4.1",
            tools=[{"type": "web_search_preview"}],
            input=query
        )
        return [{
            "title": "–û–±—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏",
            "link": "https://www.google.com/search?q=" + query.replace(" ", "+"),
            "snippet": response.output_text
        }]
    except Exception as e:
        logging.warning(f"OpenAI web_search_preview error: {e}")
        return []

async def open_url(url: str) -> str:
    headers = {"User-Agent": "Mozilla/5.0 (compatible; PublicConsultBot/1.0)"}
    try:
        async with httpx.AsyncClient(timeout=30, headers=headers) as client:
            r = await client.get(url, follow_redirects=True)
            r.raise_for_status()
            return clean_html(r.text)[:15000]
    except Exception as e:
        logging.warning(f"open_url error for {url}: {e}")
        return f"__FETCH_ERROR__: {e}"

class Pipeline:
    class Valves(BaseModel):
        MODEL_ID: str = "gpt-4.1"
        TEMPERATURE: float = 0.5
        MAX_TOKENS: int = 2000
        OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")

    def __init__(self):
        self.name = "Public Consultation Comment Analyzer"
        self.valves = self.Valves()
        self.client = OpenAI(api_key=self.valves.OPENAI_API_KEY)

    async def on_startup(self):
        logging.info("Pipeline is warming up...")

    async def on_shutdown(self):
        logging.info("Pipeline is shutting down...")

    async def make_request_with_retry(self, fn: Callable[[], Iterator[str]], retries=3) -> Iterator[str]:
        for attempt in range(retries):
            try:
                return fn()
            except Exception as e:
                logging.error(f"Attempt {attempt + 1} failed: {e}")
                if attempt + 1 == retries:
                    raise
                await asyncio.sleep(2 ** attempt)

    async def inlet(self, body: dict, user: dict) -> dict:
        logging.info("üì• Inlet body:")

        extracted = []
        for f in body.get("files", []):
            content_url = f["url"] + "/content"
            async with httpx.AsyncClient(timeout=30) as c:
                resp = await c.get(content_url)
                resp.raise_for_status()
                content = resp.content
            mime = f.get("mime_type") or mimetypes.guess_type(f.get("name", ""))[0]
            if mime == "application/pdf":
                doc = fitz.open(stream=content, filetype="pdf")
                extracted.append("\n".join(p.get_text() for p in doc))
            elif mime == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
                with open("_tmp.docx", "wb") as tmp:
                    tmp.write(content)
                extracted.append(docx2txt.process("_tmp.docx"))
                os.remove("_tmp.docx")
            elif mime and mime.startswith("image/"):
                b64 = base64.b64encode(content).decode()
                res = self.client.chat.completions.create(
                    model=self.valves.MODEL_ID,
                    messages=[{"role": "user", "content": [
                        {"type": "text", "text": "–†–∞—Å–ø–æ–∑–Ω–∞–π —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."},
                        {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{b64}"}}
                    ]}]
                )
                extracted.append(res.choices[0].message.content.strip())
        body["file_text"] = "\n".join(extracted)

        if body.get("query"):
            search_results = await web_search(body["query"])
            search_texts = []
            for res in search_results:
                if _is_trusted(res["link"]):
                    html = await open_url(res["link"])
                    search_texts.append(f"–ò—Å—Ç–æ—á–Ω–∏–∫: {res['link']}\n{html}")
            body["search_comments"] = "\n---\n".join(search_texts)

        return body

    def pipe(self, user_message: str, model_id: str, messages: List[dict], body: dict) -> Iterator[str]:
        if body.get("file_text"):
            user_message += "\n\n–¢–µ–∫—Å—Ç –∏–∑ –ø—Ä–∏–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:\n" + body["file_text"]
        if body.get("search_comments"):
            user_message += "\n\n–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–µ –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏:\n" + body["search_comments"]

        system_message = """
**–†–æ–ª—å:** –í—ã ‚Äî –∞–Ω–∞–ª–∏—Ç–∏–∫ –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π –ø—Ä–∏ –ú–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–µ —é—Å—Ç–∏—Ü–∏–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞. –í–∞—à–∞ –∑–∞–¥–∞—á–∞ ‚Äî –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –≥—Ä–∞–∂–¥–∞–Ω –∫ –∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç–∞–º, –≤—ã—è–≤–ª—è—Ç—å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏ –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏, –∏ –Ω–∞ –∏—Ö –æ—Å–Ω–æ–≤–µ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –¥–æ—Ä–∞–±–æ—Ç–∫–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Ä–µ–¥–∞–∫—Ü–∏–∏ –∑–∞–∫–æ–Ω–∞.

---

## üî¢ **–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞):**

### **–í—Å—Ç—É–ø–ª–µ–Ω–∏–µ**
–ö—Ä–∞—Ç–∫–æ –æ–ø–∏—à–∏—Ç–µ —Ü–µ–ª—å –∞–Ω–∞–ª–∏–∑–∞, –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏ –ø–æ–¥—Ö–æ–¥.

---

### **1. –ö–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∏ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑**
- **–í—Å–µ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤:** [—á–∏—Å–ª–æ]
- **–ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö:** [—á–∏—Å–ª–æ] ([%])
- **–ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö:** [—á–∏—Å–ª–æ] ([%])
- **–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö:** [—á–∏—Å–ª–æ] ([%])

#### **–û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ–º—ã:**
- ‚úî –¢–µ–º–∞ 1 (—É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –≤ X% –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤)
- ‚úî –¢–µ–º–∞ 2 ...

#### **–û—Å–Ω–æ–≤–Ω—ã–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –æ–ø–∞—Å–µ–Ω–∏—è:**
- ‚ö† –¢–µ–º–∞ 1 (–≤ Y% –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤)
- ‚ö† –¢–µ–º–∞ 2 ...

#### **–û–±—â–∏–µ —Ç—Ä–µ–Ω–¥—ã:**
- –ú–Ω–æ–∂–µ—Å—Ç–≤–æ —Å—Ö–æ–∂–∏—Ö –æ–ø–∞—Å–µ–Ω–∏–π –ø–æ —Ç–µ–º–µ...
- –ü–æ–≤—Ç–æ—Ä—è—é—â–∞—è—Å—è –ø—Ä–æ—Å—å–±–∞ –æ...

---

### **2. –ü–æ –∫–∞–∂–¥–æ–º—É –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—é:**

#### **–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: "[–≤—Å—Ç–∞–≤–∏—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π]"**
üîπ **–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:** (–ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π / –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π / –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π)  
üîπ **–ê–Ω–∞–ª–∏–∑:**  
[–ö—Ä–∞—Ç–∫–∏–π —Ä–∞–∑–±–æ—Ä —Å—É—Ç–∏, –º–æ—Ç–∏–≤–∞—Ü–∏–∏, –ª–æ–≥–∏–∫–∏, –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤]

üîπ **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**  
- [–ß—ë—Ç–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: –ø–æ—è—Å–Ω–∏—Ç—å, –∏–∑–º–µ–Ω–∏—Ç—å, —É—á–µ—Å—Ç—å, –æ—Ç–∫–ª–æ–Ω–∏—Ç—å –∏ –æ–±–æ—Å–Ω–æ–≤–∞—Ç—å]

---

(–ø–æ–≤—Ç–æ—Ä–∏—Ç—å –±–ª–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è)

---

### **3. –ò—Ç–æ–≥–æ–≤–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ**
- –û–±–æ–±—â–∏—Ç–µ –∫–ª—é—á–µ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –≤—Å–µ—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.
- –í—ã–¥–µ–ª–∏—Ç–µ, –∫–∞–∫–∏–µ –ø—Ä–∞–≤–∫–∏ —Å—Ç–æ–∏—Ç –æ–±—Å—É–¥–∏—Ç—å –∏–ª–∏ –ø—Ä–∏–Ω—è—Ç—å.
- –ï—Å–ª–∏ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –º–Ω–µ–Ω–∏–π –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏—Ç–µ –ø–æ–¥—Ö–æ–¥ –∫ —Ä–µ–∞–≥–∏—Ä–æ–≤–∞–Ω–∏—é (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–∑—ä—è—Å–Ω–µ–Ω–∏—è, —Å–µ—Å—Å–∏—è Q&A, —Å–º—è–≥—á–µ–Ω–∏–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫).

---

## üß† –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:

- –°—Ç–∏–ª—å: –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π, —É–≤–∞–∂–∏—Ç–µ–ª—å–Ω—ã–π, –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π
- –ö–∞–∂–¥—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ
- –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π—Ç–µ –º–Ω–µ–Ω–∏—è ‚Äî —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
- –ï—Å–ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –º–∞–ª–æ ‚Äî –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ
- –ù–µ –∏–∑–±–µ–≥–∞–π—Ç–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: —É–∫–∞–∑—ã–≤–∞–π—Ç–µ –ø—Ä–æ—Ü–µ–Ω—Ç—ã, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, –¥–∏–Ω–∞–º–∏–∫—É
"""

        async def _generate() -> str:
            try:
                response = self.client.responses.create(
                    model="gpt-4.1",
                    tools=[{"type": "web_search_preview"}],
                    input=f"{system_msg}\n\n<–ø—Ä–æ–µ–∫—Ç>\n{user_message}"
                )
                return response.output_text
            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
                return "‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑."

        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        return loop.run_until_complete(_generate())
