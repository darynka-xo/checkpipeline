import logging
import sys
import os
import asyncio
import re
import httpx
import mimetypes
import base64
import io
from typing import List, Iterator, Callable, Dict

from pydantic import BaseModel
from PIL import Image
import fitz  # PyMuPDF
import docx2txt
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate

logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))

TRUSTED_DOMAINS = [
    "open.zakon.kz", "legalacts.egov.kz", "adilet.zan.kz",
    "online.zakon.kz", "egov.kz", "eotinish.kz", "tengrinews.kz",
    "kursiv.media", "inbusiness.kz", "kapital.kz"
]

def _is_trusted(url: str) -> bool:
    return any(d in url for d in TRUSTED_DOMAINS)

def clean_html(text: str) -> str:
    text = re.sub(r"<[^>]+>", " ", text)
    text = re.sub(r"\s+", " ", text)
    return text.strip()

async def web_search(query: str) -> List[Dict[str, str]]:
    try:
        from openai import OpenAI
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        response = client.responses.create(
            model="gpt-4.1",
            tools=[{"type": "web_search_preview"}],
            input=query
        )
        return [{
            "title": "ĞĞ±Ñ‰ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¸",
            "link": "https://www.google.com/search?q=" + query.replace(" ", "+"),
            "snippet": response.output_text
        }]
    except Exception as e:
        logging.warning(f"OpenAI web_search_preview error: {e}")
        return []

async def open_url(url: str) -> str:
    headers = {"User-Agent": "Mozilla/5.0 (compatible; PublicConsultBot/1.0)"}
    try:
        async with httpx.AsyncClient(timeout=30, headers=headers) as client:
            r = await client.get(url, follow_redirects=True)
            r.raise_for_status()
            return clean_html(r.text)[:15000]
    except Exception as e:
        logging.warning(f"open_url error for {url}: {e}")
        return f"__FETCH_ERROR__: {e}"

class Pipeline:
    class Valves(BaseModel):
        MODEL_ID: str = "gpt-4o"
        TEMPERATURE: float = 0.5
        MAX_TOKENS: int = 2000
        OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")

    def __init__(self):
        self.name = "Public Consultation Comment Analyzer"
        self.valves = self.Valves()

    async def on_startup(self):
        logging.info("Pipeline is warming up...")

    async def on_shutdown(self):
        logging.info("Pipeline is shutting down...")

    async def make_request_with_retry(self, fn: Callable[[], Iterator[str]], retries=3) -> Iterator[str]:
        for attempt in range(retries):
            try:
                return fn()
            except Exception as e:
                logging.error(f"Attempt {attempt + 1} failed: {e}")
                if attempt + 1 == retries:
                    raise
                await asyncio.sleep(2 ** attempt)

    async def inlet(self, body: dict, user: dict) -> dict:
        logging.info("ğŸ“¥ Inlet body:")

        extracted = []
        for f in body.get("files", []):
            content_url = f["url"] + "/content"
            async with httpx.AsyncClient(timeout=30) as c:
                resp = await c.get(content_url)
                resp.raise_for_status()
                content = resp.content
            mime = f.get("mime_type") or mimetypes.guess_type(f.get("name", ""))[0]
            if mime == "application/pdf":
                doc = fitz.open(stream=content, filetype="pdf")
                extracted.append("\n".join(p.get_text() for p in doc))
            elif mime == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
                with open("_tmp.docx", "wb") as tmp:
                    tmp.write(content)
                extracted.append(docx2txt.process("_tmp.docx"))
                os.remove("_tmp.docx")
            elif mime and mime.startswith("image/"):
                from openai import OpenAI
                client = OpenAI(api_key=self.valves.OPENAI_API_KEY)
                b64 = base64.b64encode(content).decode()
                res = client.chat.completions.create(
                    model=self.valves.MODEL_ID,
                    messages=[{"role": "user", "content": [
                        {"type": "text", "text": "Ğ Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ğ½Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¸."},
                        {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{b64}"}}
                    ]}]
                )
                extracted.append(res.choices[0].message.content.strip())
        body["file_text"] = "\n".join(extracted)

        if body.get("query"):
            search_results = await web_search(body["query"])
            search_texts = []
            for res in search_results:
                if _is_trusted(res["link"]):
                    html = await open_url(res["link"])
                    search_texts.append(f"Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº: {res['link']}\n{html}")
            body["search_comments"] = "\n---\n".join(search_texts)

        return body

    def pipe(self, user_message: str, model_id: str, messages: List[dict], body: dict) -> Iterator[str]:
        if body.get("file_text"):
            user_message += "\n\nĞ¢ĞµĞºÑÑ‚ Ğ¸Ğ· Ğ¿Ñ€Ğ¸ĞºÑ€ĞµĞ¿Ğ»Ñ‘Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²:\n" + body["file_text"]
        if body.get("search_comments"):
            user_message += "\n\nĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ğ¸ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞ¹ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ Ğ¾Ğ±Ñ‰ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¸:\n" + body["search_comments"]

        system_message = """
**Ğ Ğ¾Ğ»ÑŒ:** Ğ’Ñ‹ â€” Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ğº Ğ¾Ğ±Ñ‰ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… ĞºĞ¾Ğ½ÑÑƒĞ»ÑŒÑ‚Ğ°Ñ†Ğ¸Ğ¹ Ğ¿Ñ€Ğ¸ ĞœĞ¸Ğ½Ğ¸ÑÑ‚ĞµÑ€ÑÑ‚Ğ²Ğµ ÑÑÑ‚Ğ¸Ñ†Ğ¸Ğ¸ ĞšĞ°Ğ·Ğ°Ñ…ÑÑ‚Ğ°Ğ½Ğ°. Ğ’Ğ°ÑˆĞ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° â€” Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¸ Ğ³Ñ€Ğ°Ğ¶Ğ´Ğ°Ğ½ Ğº Ğ·Ğ°ĞºĞ¾Ğ½Ğ¾Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°Ğ¼, Ğ²Ñ‹ÑĞ²Ğ»ÑÑ‚ÑŒ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ Ğ¸ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ñ‚ĞµĞ½Ğ´ĞµĞ½Ñ†Ğ¸Ğ¸, Ğ¸ Ğ½Ğ° Ğ¸Ñ… Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ Ğ´Ğ¾Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ñ€ĞµĞ´Ğ°ĞºÑ†Ğ¸Ğ¸ Ğ·Ğ°ĞºĞ¾Ğ½Ğ°.

---

## ğŸ”¢ **Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° (ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ°):**

### **Ğ’ÑÑ‚ÑƒĞ¿Ğ»ĞµĞ½Ğ¸Ğµ**
ĞšÑ€Ğ°Ñ‚ĞºĞ¾ Ğ¾Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ Ñ†ĞµĞ»ÑŒ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°, Ğ¾Ğ±Ñ‰ĞµĞµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸ĞµĞ² Ğ¸ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´.

---

### **1. ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¸ Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·**
- **Ğ’ÑĞµĞ³Ğ¾ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸ĞµĞ²:** [Ñ‡Ğ¸ÑĞ»Ğ¾]
- **ĞŸĞ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ…:** [Ñ‡Ğ¸ÑĞ»Ğ¾] ([%])
- **ĞĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ…:** [Ñ‡Ğ¸ÑĞ»Ğ¾] ([%])
- **ĞĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ñ‹Ñ…:** [Ñ‡Ğ¸ÑĞ»Ğ¾] ([%])

#### **ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ‚ĞµĞ¼Ñ‹:**
- âœ” Ğ¢ĞµĞ¼Ğ° 1 (ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ Ğ² X% ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸ĞµĞ²)
- âœ” Ğ¢ĞµĞ¼Ğ° 2 ...

#### **ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¾Ğ¿Ğ°ÑĞµĞ½Ğ¸Ñ:**
- âš  Ğ¢ĞµĞ¼Ğ° 1 (Ğ² Y% ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸ĞµĞ²)
- âš  Ğ¢ĞµĞ¼Ğ° 2 ...

#### **ĞĞ±Ñ‰Ğ¸Ğµ Ñ‚Ñ€ĞµĞ½Ğ´Ñ‹:**
- ĞœĞ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²Ğ¾ ÑÑ…Ğ¾Ğ¶Ğ¸Ñ… Ğ¾Ğ¿Ğ°ÑĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ Ñ‚ĞµĞ¼Ğµ...
- ĞŸĞ¾Ğ²Ñ‚Ğ¾Ñ€ÑÑÑ‰Ğ°ÑÑÑ Ğ¿Ñ€Ğ¾ÑÑŒĞ±Ğ° Ğ¾...

---

### **2. ĞŸĞ¾ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼Ñƒ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ñ:**

#### **ĞšĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹: "[Ğ²ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹]"**
ğŸ”¹ **Ğ¢Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ:** (Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ / Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ / Ğ½ĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹)  
ğŸ”¹ **ĞĞ½Ğ°Ğ»Ğ¸Ğ·:**  
[ĞšÑ€Ğ°Ñ‚ĞºĞ¸Ğ¹ Ñ€Ğ°Ğ·Ğ±Ğ¾Ñ€ ÑÑƒÑ‚Ğ¸, Ğ¼Ğ¾Ñ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¸, Ğ»Ğ¾Ğ³Ğ¸ĞºĞ¸, Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ¾Ğ²]

ğŸ”¹ **Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸:**  
- [Ğ§Ñ‘Ñ‚ĞºĞ¸Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ: Ğ¿Ğ¾ÑÑĞ½Ğ¸Ñ‚ÑŒ, Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ, ÑƒÑ‡ĞµÑÑ‚ÑŒ, Ğ¾Ñ‚ĞºĞ»Ğ¾Ğ½Ğ¸Ñ‚ÑŒ Ğ¸ Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ñ‚ÑŒ]

---

(Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ñ‚ÑŒ Ğ±Ğ»Ğ¾Ğº Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ñ)

---

### **3. Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğµ Ğ·Ğ°ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ**
- ĞĞ±Ğ¾Ğ±Ñ‰Ğ¸Ñ‚Ğµ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ²ÑĞµÑ… ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸ĞµĞ².
- Ğ’Ñ‹Ğ´ĞµĞ»Ğ¸Ñ‚Ğµ, ĞºĞ°ĞºĞ¸Ğµ Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸ ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ¾Ğ±ÑÑƒĞ´Ğ¸Ñ‚ÑŒ Ğ¸Ğ»Ğ¸ Ğ¿Ñ€Ğ¸Ğ½ÑÑ‚ÑŒ.
- Ğ•ÑĞ»Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ½ÑÑ‚Ğ²Ğ¾ Ğ¼Ğ½ĞµĞ½Ğ¸Ğ¹ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ â€” Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ñ‚Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ñ€ĞµĞ°Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ€Ğ°Ğ·ÑŠÑÑĞ½ĞµĞ½Ğ¸Ñ, ÑĞµÑÑĞ¸Ñ Q&A, ÑĞ¼ÑĞ³Ñ‡ĞµĞ½Ğ¸Ğµ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ¾Ğº).

---

## ğŸ§  Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸:

- Ğ¡Ñ‚Ğ¸Ğ»ÑŒ: Ğ¾Ñ„Ğ¸Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹, ÑƒĞ²Ğ°Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹, Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹
- ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾
- ĞĞµ Ğ²Ñ‹Ğ´ÑƒĞ¼Ñ‹Ğ²Ğ°Ğ¹Ñ‚Ğµ Ğ¼Ğ½ĞµĞ½Ğ¸Ñ â€” Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ„Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ°
- Ğ•ÑĞ»Ğ¸ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸ĞµĞ² Ğ¼Ğ°Ğ»Ğ¾ â€” Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾
- ĞĞµ Ğ¸Ğ·Ğ±ĞµĞ³Ğ°Ğ¹Ñ‚Ğµ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸: ÑƒĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ğ¹Ñ‚Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚Ñ‹, ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾, Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºÑƒ
"""

        model = ChatOpenAI(
            api_key=self.valves.OPENAI_API_KEY,
            model=self.valves.MODEL_ID,
            temperature=self.valves.TEMPERATURE,
            streaming=True
        )

        prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(system_message),
            HumanMessagePromptTemplate.from_template("{user_input}")
        ])

        formatted_messages = prompt.format_messages(user_input=user_message)

        def generate_stream() -> Iterator[str]:
            for chunk in model.stream(formatted_messages):
                content = getattr(chunk, "content", None)
                if content:
                    logging.debug(f"Model chunk: {content}")
                    yield content

        return asyncio.run(self.make_request_with_retry(generate_stream))
