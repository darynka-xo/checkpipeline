import logging
import sys
import os
import asyncio
import re
import httpx
import mimetypes
import base64
import io
from typing import List, Iterator, Callable, Dict

from pydantic import BaseModel
from langchain_openai import ChatOpenAI
from langchain.tools import Tool
from langchain.agents import initialize_agent, AgentType

# Optional imports for fileâ€‘text extraction
from PIL import Image
import fitz                     # PyMuPDF
import docx2txt                 # .docx -> text

###############################################################################
# Logging
###############################################################################
logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))

###############################################################################
# Helper tools for the LLM agent
###############################################################################
SERPER_API_KEY = os.getenv("SERPER_API_KEY", "")
TRUSTED_DOMAINS = [
    "akorda.kz", "senate.parlam.kz", "primeminister.kz",
    "otyrys.prk.kz", "senate-zan.prk.kz", "lib.prk.kz",
    "online.zakon.kz", "adilet.zan.kz", "legalacts.egov.kz",
    "egov.kz", "eotinish.kz"
]

def _is_trusted(url: str) -> bool:
    return any(d in url for d in TRUSTED_DOMAINS)

def clean_html(text: str) -> str:
    text = re.sub(r"<[^>]+>", " ", text)  # remove tags
    text = re.sub(r"\s+", " ", text)
    return text.strip()

async def web_search(query: str) -> List[Dict[str, str]]:
    headers = {"X-API-KEY": SERPER_API_KEY, "Content-Type": "application/json"}
    try:
        async with httpx.AsyncClient(timeout=20) as client:
            r = await client.post(
                "https://google.serper.dev/search",
                json={"q": query, "num": 10},
                headers=headers,
            )
            r.raise_for_status()
            items = r.json().get("organic", [])
    except Exception as e:
        logging.warning(f"Serper error for '{query}': {e}")
        return []
    return [
        {"title": it["title"], "link": it["link"], "snippet": it.get("snippet", "")}
        for it in items
        if _is_trusted(it["link"])
    ]


async def open_url(url: str) -> str:
    headers = {"User-Agent": "Mozilla/5.0 (compatible; LawExpBot/1.0)"}
    try:
        async with httpx.AsyncClient(timeout=30, headers=headers) as client:
            r = await client.get(url, follow_redirects=True)
            r.raise_for_status()
            return clean_html(r.text)[:15000]
    except Exception as e:
        logging.warning(f"open_url error for {url}: {e}")
        return f"__FETCH_ERROR__: {e}"


# Wrap as LangChain tools
SEARCH_TOOL = Tool.from_function(
    name="web_search",
    description="ÐÐ°Ð¹Ð´Ð¸ Ð¾Ñ„Ð¸Ñ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð¸ ÑÑ‚Ð°Ñ‚ÑŒÐ¸ ÐºÐ°Ð·Ð°Ñ…ÑÑ‚Ð°Ð½ÑÐºÐ¸Ñ… Ð³Ð¾Ñâ€‘ÑÐ°Ð¹Ñ‚Ð¾Ð² Ð¿Ð¾ Ð·Ð°Ð´Ð°Ð½Ð½Ð¾Ð¼Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ (Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼). Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð² {title, link, snippet}.",
    func=web_search,
)
FETCH_TOOL = Tool.from_function(
    name="open_url",
    description="Ð¡ÐºÐ°Ñ‡Ð°Ð¹ HTML ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹ Ð¿Ð¾ URL Ð¸ Ð²ÐµÑ€Ð½Ð¸ Ñ‡Ð¸ÑÑ‚Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð±ÐµÐ· Ñ‚ÐµÐ³Ð¾Ð². Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð»Ñ ÑÑÑ‹Ð»Ð¾Ðº Ñ Ð³Ð¾Ñâ€‘ÑÐ°Ð¹Ñ‚Ð¾Ð².",
    func=open_url,
)

###############################################################################
# The OpenWebUI Pipeline
###############################################################################
class Pipeline:
    class Valves(BaseModel):
        MODEL_ID: str = "gpt-4o"
        TEMPERATURE: float = 0.3
        MAX_TOKENS: int = 1800
        OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")

    def __init__(self):
        self.name = "Ð­ÐºÑÐ¿ÐµÑ€Ñ‚ Ð¿Ð¾ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸ÑÐ¼"
        self.valves = self.Valves()

        # init LLM + toolsâ€‘powered agent
        llm = ChatOpenAI(
            api_key=self.valves.OPENAI_API_KEY,
            model=self.valves.MODEL_ID,
            temperature=self.valves.TEMPERATURE,
            max_tokens=self.valves.MAX_TOKENS,
        )
        self.agent = initialize_agent(
            [SEARCH_TOOL, FETCH_TOOL],
            llm,
            agent=AgentType.OPENAI_FUNCTIONS,
            verbose=False,
            max_iterations=12,
            max_execution_time=120,
            early_stopping_method="generate"  # Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ð±ÐµÐ· Ð¾ÑˆÐ¸Ð±Ð¾Ðº
        )

    # ---------------------------------------------------------------------
    # OpenWebUI lifeâ€‘cycle hooks
    # ---------------------------------------------------------------------
    async def on_startup(self):
        logging.info("LawExp pipeline warming upâ€¦")

    async def on_shutdown(self):
        logging.info("LawExp pipeline shutting downâ€¦")

    # ------------------------------------------------------------------
    # Helper: retry wrapper for generators (for streaming UI)
    # ------------------------------------------------------------------
    async def make_request_with_retry(self, fn: Callable[[], Iterator[str]], retries=3) -> Iterator[str]:
        for attempt in range(retries):
            try:
                return fn()
            except Exception as e:
                logging.error(f"Attempt {attempt+1} failed: {e}")
                if attempt + 1 == retries:
                    raise
                await asyncio.sleep(2 ** attempt)

    # ------------------------------------------------------------------
    # inlet: handle uploaded files â†’ OCR/extract text
    # ------------------------------------------------------------------
    async def inlet(self, body: dict, user: dict) -> dict:
        import json
        logging.info("ðŸ“¥ Inlet body:\n" + json.dumps(body, indent=2, ensure_ascii=False))

        extracted = []
        for f in body.get("files", []):
            content_url = f["url"] + "/content"
            async with httpx.AsyncClient(timeout=30) as c:
                resp = await c.get(content_url)
                resp.raise_for_status()
                content = resp.content
            mime = f.get("mime_type") or mimetypes.guess_type(f.get("name", ""))[0]
            if mime == "application/pdf":
                doc = fitz.open(stream=content, filetype="pdf")
                extracted.append("\n".join(p.get_text() for p in doc))
            elif mime == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
                with open("_tmp.docx", "wb") as tmp:
                    tmp.write(content)
                extracted.append(docx2txt.process("_tmp.docx"))
                os.remove("_tmp.docx")
            elif mime and mime.startswith("image/"):
                # cheap OCR via OpenAI Vision
                from openai import OpenAI
                client = OpenAI(api_key=self.valves.OPENAI_API_KEY)
                b64 = base64.b64encode(content).decode()
                res = client.chat.completions.create(
                    model=self.valves.MODEL_ID,
                    messages=[{"role": "user", "content": [
                        {"type": "text", "text": "Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸."},
                        {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{b64}"}}
                    ]}]
                )
                extracted.append(res.choices[0].message.content.strip())
        body["file_text"] = "\n".join(extracted)
        return body

    # ------------------------------------------------------------------
    # main pipe: build system prompt â†’ delegate to LLM agent
    # ------------------------------------------------------------------
    def pipe(self, user_message: str, model_id: str, messages: List[dict], body: dict) -> Iterator[str]:
        # attach text from uploaded files
        if body.get("file_text"):
            user_message += "\n\nÐ¢ÐµÐºÑÑ‚ Ð¸Ð· Ð¿Ñ€Ð¸ÐºÑ€ÐµÐ¿Ð»Ñ‘Ð½Ð½Ñ‹Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²:\n" + body["file_text"]

        # system instructions for the agent (NO clarifying questions!)
        system_msg = (
            "Ð¢Ñ‹ â€” Ð˜Ð˜â€‘ÑÐºÑÐ¿ÐµÑ€Ñ‚ Ð¿Ð¾ ÑÑ€Ð°Ð²Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¼Ñƒ Ð¿Ñ€Ð°Ð²Ð¾Ð²Ð¾Ð¼Ñƒ Ð°Ð½Ð°Ð»Ð¸Ð·Ñƒ. Ð¡Ñ‚Ñ€Ð¾Ð³Ð¾ ÑÐ¾Ð±Ð»ÑŽÐ´Ð°Ð¹ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°:\n"
            "â€¢ ÐÐ¸ÐºÐ¾Ð³Ð´Ð° Ð½Ðµ Ð·Ð°Ð´Ð°Ð²Ð°Ð¹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŽ ÑƒÑ‚Ð¾Ñ‡Ð½ÑÑŽÑ‰Ð¸Ñ… Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð².\n"
            "â€¢ Ð•ÑÐ»Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¼Ð°Ð»Ð¾ â€” Ð´ÐµÐ»Ð°Ð¹ Ð»ÑƒÑ‡ÑˆÐµÐµ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾Ðµ Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ð¸ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð°Ð¹.\n"
            "â€¢ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ web_search / open_url, Ð½Ð¾ Ð²Ñ‹Ð²Ð¾Ð´Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ð´Ð½Ð¸Ð¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸ÐµÐ¼.\n"
            "Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð°:\n"
            "1. ÐÐ°Ð¹Ñ‚Ð¸ Ð´ÐµÐ¹ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ Ð½Ð¾Ñ€Ð¼Ñ‹ Ð² ÐºÐ°Ð·Ð°Ñ…ÑÑ‚Ð°Ð½ÑÐºÐ¾Ð¼ Ð¿Ñ€Ð°Ð²Ðµ, Ð¿ÐµÑ€ÐµÑÐµÐºÐ°ÑŽÑ‰Ð¸ÐµÑÑ Ð¸Ð»Ð¸ Ð´ÑƒÐ±Ð»Ð¸Ñ€ÑƒÑŽÑ‰Ð¸Ðµ Ð¿Ð¾Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°.\n"
            "2. Ð¡Ð¾Ð±Ñ€Ð°Ñ‚ÑŒ ÐºÑ€Ð°Ñ‚ÐºÑƒÑŽ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð¿Ñ€Ð°Ð²Ð¾Ðº ÑÑ‚Ð¸Ñ… Ð½Ð¾Ñ€Ð¼ (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ð½Ð° adilet).\n"
            "3. Ð’Ñ‹Ð²ÐµÑÑ‚Ð¸ ðŸ“Š Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ: | â„– | Ð¡Ñ‚Ð°Ñ‚ÑŒÑ (Ð½Ð¾Ð²Ñ‹Ð¹) | Ð”ÑƒÐ±Ð»Ð¸Ñ€ÑƒÑŽÑ‰Ð°Ñ Ð½Ð¾Ñ€Ð¼Ð° | Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº | Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ Ð¿Ñ€Ð°Ð²Ð¾Ðº | ÐšÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹ |\n"
            "4. Ð’ ÐºÐ¾Ð½Ñ†Ðµ Ð´Ð°Ñ‚ÑŒ âš–ï¸ Ð˜Ñ‚Ð¾Ð³ Ñ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸ÑÐ¼Ð¸.\n"
            "ÐÐµ Ð¿Ñ€Ð¸Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹ ÑÑ‚Ð°Ñ‚ÑŒÐ¸ â€” Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ðµ." )

        async def _generate() -> str:
            prompt = f"{system_msg}\n\n<Ð¿Ñ€Ð¾ÐµÐºÑ‚>\n{user_message}"
            return await self.agent.arun(prompt)

        loop = asyncio.new_event_loop()
        asyncio.set
