import logging
import sys
import os
import asyncio
import re
import httpx
import mimetypes
import base64
import io
from typing import List, Iterator, Callable, Any, Dict

from pydantic import BaseModel
from langchain_openai import ChatOpenAI
from langchain.tools import Tool
from langchain.agents import initialize_agent, AgentType
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate

# Optional imports for fileâ€‘text extraction
from PIL import Image
import fitz                     # PyMuPDF
import docx2txt                 # .docx -> text

###############################################################################
# Logging
###############################################################################
logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))

###############################################################################
# Helper tools for the LLM agent
###############################################################################
SERPER_API_KEY = os.getenv("SERPER_API_KEY", "")
TRUSTED_DOMAINS = [
    "akorda.kz", "senate.parlam.kz", "primeminister.kz",
    "otyrys.prk.kz", "senate-zan.prk.kz", "lib.prk.kz",
    "online.zakon.kz", "adilet.zan.kz", "legalacts.egov.kz",
    "egov.kz", "eotinish.kz"
]

def _is_trusted(url: str) -> bool:
    return any(d in url for d in TRUSTED_DOMAINS)

def clean_html(text: str) -> str:
    text = re.sub(r"<[^>]+>", " ", text)  # remove tags
    text = re.sub(r"\s+", " ", text)
    return text.strip()

async def web_search(query: str) -> List[Dict[str, str]]:
    """Return up to 10 organic Google results via Serper."""
    headers = {"X-API-KEY": SERPER_API_KEY, "Content-Type": "application/json"}
    async with httpx.AsyncClient(timeout=20) as client:
        r = await client.post("https://google.serper.dev/search", json={"q": query, "num": 10}, headers=headers)
        r.raise_for_status()
        items = r.json().get("organic", [])
    # keep only trusted
    return [{"title": it["title"], "link": it["link"], "snippet": it["snippet"]}
            for it in items if _is_trusted(it["link"])]

async def open_url(url: str) -> str:
    """Fetch a URL and return cleaned text (first 15k chars)."""
    async with httpx.AsyncClient(timeout=20) as client:
        r = await client.get(url)
        r.raise_for_status()
        return clean_html(r.text)[:15000]

# Wrap as LangChain tools
SEARCH_TOOL = Tool.from_function(
    name="web_search",
    description="ÐÐ°Ð¹Ð´Ð¸ Ð¾Ñ„Ð¸Ñ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð¸ ÑÑ‚Ð°Ñ‚ÑŒÐ¸ ÐºÐ°Ð·Ð°Ñ…ÑÑ‚Ð°Ð½ÑÐºÐ¸Ñ… Ð³Ð¾Ñâ€‘ÑÐ°Ð¹Ñ‚Ð¾Ð² Ð¿Ð¾ Ð·Ð°Ð´Ð°Ð½Ð½Ð¾Ð¼Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ (Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼). Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð² {title, link, snippet}.",
    func=web_search,
)
FETCH_TOOL = Tool.from_function(
    name="open_url",
    description="Ð¡ÐºÐ°Ñ‡Ð°Ð¹ HTML ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹ Ð¿Ð¾ URL Ð¸ Ð²ÐµÑ€Ð½Ð¸ Ñ‡Ð¸ÑÑ‚Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð±ÐµÐ· Ñ‚ÐµÐ³Ð¾Ð². Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð»Ñ ÑÑÑ‹Ð»Ð¾Ðº Ñ Ð³Ð¾Ñâ€‘ÑÐ°Ð¹Ñ‚Ð¾Ð².",
    func=open_url,
)

###############################################################################
# The OpenWebUI Pipeline
###############################################################################
class Pipeline:
    class Valves(BaseModel):
        MODEL_ID: str = "gpt-4o"
        TEMPERATURE: float = 0.3
        MAX_TOKENS: int = 1800
        OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")

    def __init__(self):
        self.name = "Ð­ÐºÑÐ¿ÐµÑ€Ñ‚ Ð¿Ð¾ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸ÑÐ¼"
        self.valves = self.Valves()

        # init LLM + toolsâ€‘powered agent
        llm = ChatOpenAI(
            api_key=self.valves.OPENAI_API_KEY,
            model=self.valves.MODEL_ID,
            temperature=self.valves.TEMPERATURE,
            max_tokens=self.valves.MAX_TOKENS,
        )
        self.agent = initialize_agent(
            [SEARCH_TOOL, FETCH_TOOL],
            llm,
            agent=AgentType.OPENAI_FUNCTIONS,
            verbose=False,
            max_iterations=6,
        )

    # ---------------------------------------------------------------------
    # OpenWebUI lifeâ€‘cycle hooks
    # ---------------------------------------------------------------------
    async def on_startup(self):
        logging.info("LawExp pipeline warming upâ€¦")

    async def on_shutdown(self):
        logging.info("LawExp pipeline shutting downâ€¦")

    # ------------------------------------------------------------------
    # Helper: retry wrapper for generators (for streaming UI)
    # ------------------------------------------------------------------
    async def make_request_with_retry(self, fn: Callable[[], Iterator[str]], retries=3) -> Iterator[str]:
        for attempt in range(retries):
            try:
                return fn()
            except Exception as e:
                logging.error(f"Attempt {attempt+1} failed: {e}")
                if attempt + 1 == retries:
                    raise
                await asyncio.sleep(2 ** attempt)

    # ------------------------------------------------------------------
    # inlet: handle uploaded files â†’ OCR/extract text
    # ------------------------------------------------------------------
    async def inlet(self, body: dict, user: dict) -> dict:
        import json
        logging.info("ðŸ“¥ Inlet body:\n" + json.dumps(body, indent=2, ensure_ascii=False))

        extracted = []
        for f in body.get("files", []):
            content_url = f["url"] + "/content"
            async with httpx.AsyncClient(timeout=30) as c:
                resp = await c.get(content_url)
                resp.raise_for_status()
                content = resp.content
            mime = f.get("mime_type") or mimetypes.guess_type(f.get("name", ""))[0]
            if mime == "application/pdf":
                doc = fitz.open(stream=content, filetype="pdf")
                extracted.append("\n".join(p.get_text() for p in doc))
            elif mime == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
                with open("_tmp.docx", "wb") as tmp:
                    tmp.write(content)
                extracted.append(docx2txt.process("_tmp.docx"))
                os.remove("_tmp.docx")
            elif mime and mime.startswith("image/"):
                # cheap OCR via OpenAI Vision
                from openai import OpenAI
                client = OpenAI(api_key=self.valves.OPENAI_API_KEY)
                b64 = base64.b64encode(content).decode()
                res = client.chat.completions.create(
                    model=self.valves.MODEL_ID,
                    messages=[{"role": "user", "content": [
                        {"type": "text", "text": "Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸."},
                        {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{b64}"}}
                    ]}]
                )
                extracted.append(res.choices[0].message.content.strip())
        body["file_text"] = "\n".join(extracted)
        return body

    # ------------------------------------------------------------------
    # main pipe: build system prompt -> delegate to LLM agent (search + analyse)
    # ------------------------------------------------------------------
    def pipe(self, user_message: str, model_id: str, messages: List[dict], body: dict) -> Iterator[str]:
        # attach text from uploaded files
        if body.get("file_text"):
            user_message += "\n\nÐ¢ÐµÐºÑÑ‚ Ð¸Ð· Ð¿Ñ€Ð¸ÐºÑ€ÐµÐ¿Ð»Ñ‘Ð½Ð½Ñ‹Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²:\n" + body["file_text"]

        # system instructions for the agent
        system_msg = (
            "Ð¢Ñ‹ â€” Ð˜Ð˜â€‘ÑÐºÑÐ¿ÐµÑ€Ñ‚ Ð¿Ð¾ ÑÑ€Ð°Ð²Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¼Ñƒ Ð¿Ñ€Ð°Ð²Ð¾Ð²Ð¾Ð¼Ñƒ Ð°Ð½Ð°Ð»Ð¸Ð·Ñƒ. "
            "ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ð² Ñ‡ÐµÑ€Ð½Ð¾Ð²Ð¸Ðº Ð·Ð°ÐºÐ¾Ð½Ð¾Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°, Ñ‚Ñ‹ Ð´Ð¾Ð»Ð¶ÐµÐ½: \n"
            "1. ÐÐ°Ð¹Ñ‚Ð¸ Ð´ÐµÐ¹ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ Ð½Ð¾Ñ€Ð¼Ñ‹ Ð² ÐºÐ°Ð·Ð°Ñ…ÑÑ‚Ð°Ð½ÑÐºÐ¾Ð¼ Ð¿Ñ€Ð°Ð²Ðµ, Ð¿ÐµÑ€ÐµÑÐµÐºÐ°ÑŽÑ‰Ð¸ÐµÑÑ Ð¸Ð»Ð¸ Ð´ÑƒÐ±Ð»Ð¸Ñ€ÑƒÑŽÑ‰Ð¸Ðµ Ð¿Ð¾Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°.\n"
            "2. Ð¡Ð¾Ð±Ñ€Ð°Ñ‚ÑŒ ÐºÑ€Ð°Ñ‚ÐºÑƒÑŽ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð¿Ñ€Ð°Ð²Ð¾Ðº ÑÑ‚Ð¸Ñ… Ð½Ð¾Ñ€Ð¼ (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ð½Ð° adilet).\n"
            "3. Ð’Ñ‹Ð²ÐµÑÑ‚Ð¸ ðŸ“Š Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ: | â„– | Ð¡Ñ‚Ð°Ñ‚ÑŒÑ (Ð½Ð¾Ð²Ñ‹Ð¹) | Ð”ÑƒÐ±Ð»Ð¸Ñ€ÑƒÑŽÑ‰Ð°Ñ Ð½Ð¾Ñ€Ð¼Ð° | Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº | Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ Ð¿Ñ€Ð°Ð²Ð¾Ðº | ÐšÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹ |\n"
            "4. Ð’ ÐºÐ¾Ð½Ñ†Ðµ Ð´Ð°Ñ‚ÑŒ âš–ï¸ Ð˜Ñ‚Ð¾Ð³ Ñ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸ÑÐ¼Ð¸.\n"
            "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ web_search Ð¸ open_url ÐºÐ¾Ð³Ð´Ð° Ð½ÑƒÐ¶Ð½Ð¾. ÐÐµ Ð¿Ñ€Ð¸Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹ ÑÑ‚Ð°Ñ‚ÑŒÐ¸ â€” Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ðµ." )

        async def _generate() -> str:
            # we concatenate system + user as a single agent prompt
            prompt = f"{system_msg}\n\n<Ð¿Ñ€Ð¾ÐµÐºÑ‚>\n{user_message}"
            return await self.agent.arun(prompt)

        # run synchronously from sync context
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            result = loop.run_until_complete(_generate())
        finally:
            loop.close()

        def _stream_once():
            yield result
        return _stream_once()
