import logging
import sys
import os
import asyncio
from typing import List, Iterator, Callable
from pydantic import BaseModel
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate

logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))


class Pipeline:
    class Valves(BaseModel):
        MODEL_ID: str = "gpt-4o"
        TEMPERATURE: float = 0.4
        MAX_TOKENS: int = 1500
        OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")

    def __init__(self):
        self.name = "Press Release Generator"
        self.valves = self.Valves()

    async def on_startup(self):
        logging.info("Pipeline is warming up...")

    async def on_shutdown(self):
        logging.info("Pipeline is shutting down...")

    async def make_request_with_retry(self, fn: Callable[[], Iterator[str]], retries=3) -> Iterator[str]:
        for attempt in range(retries):
            try:
                return fn()
            except Exception as e:
                logging.error(f"Attempt {attempt + 1} failed: {e}")
                if attempt + 1 == retries:
                    raise
                await asyncio.sleep(2 ** attempt)
    async def inlet(self, body: dict, user: dict) -> dict:
        import json
        logging.info("ðŸ“¥ Inlet body:\n" + json.dumps(body, indent=2, ensure_ascii=False))
    
        extracted = []
        for f in body.get("files", []):
            url = f.get("url", "")
            content = None
    
            if url.startswith("http://") or url.startswith("https://"):
                content_url = url + "/content"
                async with httpx.AsyncClient(timeout=30) as c:
                    resp = await c.get(content_url)
                    resp.raise_for_status()
                    content = resp.content
            elif url.startswith("data:"):
                # ÐŸÑ€Ð¸Ð¼ÐµÑ€: data:application/vnd.openxmlformats-officedocument.wordprocessingml.document;base64,...
                header, b64data = url.split(",", 1)
                content = base64.b64decode(b64data)
            else:
                logging.warning(f"âš ï¸ Unsupported or missing URL scheme: {url}")
                continue
    
            mime = f.get("mime_type") or mimetypes.guess_type(f.get("name", ""))[0]
            if mime == "application/pdf":
                doc = fitz.open(stream=content, filetype="pdf")
                extracted.append("\n".join(p.get_text() for p in doc))
            elif mime == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
                with open("_tmp.docx", "wb") as tmp:
                    tmp.write(content)
                extracted.append(docx2txt.process("_tmp.docx"))
                os.remove("_tmp.docx")
            elif mime and mime.startswith("image/"):
                b64 = base64.b64encode(content).decode()
                res = self.client.chat.completions.create(
                    model=self.valves.MODEL_ID,
                    messages=[{"role": "user", "content": [
                        {"type": "text", "text": "Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸."},
                        {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{b64}"}}
                    ]}]
                )
                extracted.append(res.choices[0].message.content.strip())
    
        body["file_text"] = "\n".join(extracted)
        return body

    def pipe(
        self, user_message: str, model_id: str, messages: List[dict], body: dict
    ) -> Iterator[str]:
        if body.get("file_text"):
            user_message += "\n\nÐ¢ÐµÐºÑÑ‚ Ð¸Ð· Ð¿Ñ€Ð¸ÐºÑ€ÐµÐ¿Ð»Ñ‘Ð½Ð½Ñ‹Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²:\n" + body["file_text"]
        system_message = """
**Ð Ð¾Ð»ÑŒ:** Ð’Ñ‹ â€” Ð¾Ð¿Ñ‹Ñ‚Ð½Ñ‹Ð¹ PR-ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚ Ð¿Ñ€Ð¸ Ð¡ÐµÐ½Ð°Ñ‚Ðµ Ð ÐµÑÐ¿ÑƒÐ±Ð»Ð¸ÐºÐ¸ ÐšÐ°Ð·Ð°Ñ…ÑÑ‚Ð°Ð½. Ð’Ð°ÑˆÐ° Ð·Ð°Ð´Ð°Ñ‡Ð° â€” ÑÐ¾Ð·Ð´Ð°Ð²Ð°Ñ‚ÑŒ Ð¾Ñ„Ð¸Ñ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ñ€ÐµÐ»Ð¸Ð·Ñ‹ Ð¸ Ð¿Ð¾ÑÑÐ½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð·Ð°Ð¿Ð¸ÑÐºÐ¸ Ð¿Ð¾ Ð·Ð°ÐºÐ¾Ð½Ð¾Ð´Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ñ‚Ð¸Ð²Ð°Ð¼.

---

**Ð ÐµÐ¶Ð¸Ð¼Ñ‹ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹:**
- ÐŸÐ¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ **ÐšÑ€Ð°Ñ‚ÐºÐ¸Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚** (Ð´Ð»Ñ ÐºÐ¾Ð¼Ð¸Ñ‚ÐµÑ‚Ð°): Ð»Ð°ÐºÐ¾Ð½Ð¸Ñ‡Ð½Ñ‹Ð¹ Ð¿Ñ€ÐµÑÑ-Ñ€ÐµÐ»Ð¸Ð· Ð½Ð° 2â€“3 Ð°Ð±Ð·Ð°Ñ†Ð°.
- Ð•ÑÐ»Ð¸ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾ "Ð´Ð»Ñ Ñ€ÑƒÐºÐ¾Ð²Ð¾Ð´ÑÑ‚Ð²Ð°" â€” Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ **ÐžÐ±ÑŠÑ‘Ð¼Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚** Ñ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ñ‹Ð¼Ð¸ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸ÑÐ¼Ð¸, Ð¾Ð±Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ð¸ÑÐ¼Ð¸ Ð¸ Ð²ÑÐµÐ¼Ð¸ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ð¼Ð¸ Ð±Ð»Ð¾ÐºÐ°Ð¼Ð¸.
- Ð•ÑÐ»Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð¿Ñ€Ð¸ÐºÑ€ÐµÐ¿Ð¸Ð» Ñ„Ð°Ð¹Ð» ÑˆÐ°Ð±Ð»Ð¾Ð½Ð° Ð¸Ð· Ð¡ÐµÐ½Ð°Ñ‚Ð° â€” Ð²Ñ‹ ÑÐ»ÐµÐ´ÑƒÐµÑ‚Ðµ ÐµÐ¼Ñƒ, ÑƒÑ‚Ð¾Ñ‡Ð½ÑÑ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ Ñƒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¿Ñ€Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸.

---

**ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸:**
- ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð¿Ñ€ÐµÑÑ-Ñ€ÐµÐ»Ð¸Ð·Ð° Ñ ÑƒÑ‡Ñ‘Ñ‚Ð¾Ð¼:
  - ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ñ Ð·Ð°ÐºÐ¾Ð½Ð¾Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
  - Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ñ‚Ð¾Ñ€Ð°
  - Ð¦ÐµÐ»Ð¸ Ð·Ð°ÐºÐ¾Ð½Ð¾Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
  - Ð¢ÐµÐºÑƒÑ‰ÐµÐ³Ð¾ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ð¸Ð»Ð¸ ÑÑ‚Ð°Ð´Ð¸Ð¸ Ð¾Ð±ÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ
- Ð¡Ñ‚Ð¸Ð»Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¾Ñ„Ð¸Ñ†Ð¸Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ ÑÐ·Ñ‹ÐºÐ°
- Ð’ÑÑ‚Ð°Ð²ÐºÐ° Ð´Ð¾ÑÑ‚Ð¾Ð²ÐµÑ€Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸, ÐµÑÐ»Ð¸ Ð·Ð°Ð¿Ñ€Ð¾ÑˆÐµÐ½Ð¾
- Ð“Ð¾Ñ‚Ð¾Ð²Ð½Ð¾ÑÑ‚ÑŒ Ðº Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÑŽ Ð¿Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ: _"Ð£Ð±ÐµÑ€Ð¸ ÑÑ‚Ð¾"_, _"Ð¡Ð´ÐµÐ»Ð°Ð¹ ÐºÐ¾Ñ€Ð¾Ñ‡Ðµ"_, _"Ð”Ð¾Ð±Ð°Ð²ÑŒ Ñ†Ð¸Ñ„Ñ€Ñ‹"_

---

**Ð•ÑÐ»Ð¸ Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾ Ð¸Ð½Ð¾Ðµ, Ð²Ñ‹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚Ðµ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¹ ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð½Ð¸Ð¶Ðµ:**

### **ÐŸÑ€ÐµÑÑ-Ñ€ÐµÐ»Ð¸Ð·: [ÑƒÐºÐ°Ð·Ð°Ñ‚ÑŒ Ñ‚ÐµÐ¼Ñƒ]**
**Ð”Ð°Ñ‚Ð°: [ÑÐµÐ³Ð¾Ð´Ð½ÑÑˆÐ½ÑÑ Ð´Ð°Ñ‚Ð°]**  
**ÐœÐµÑÑ‚Ð¾: ÐÑÑ‚Ð°Ð½Ð°, ÐšÐ°Ð·Ð°Ñ…ÑÑ‚Ð°Ð½**

### **ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ð¿Ð¾Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ**
- ÐšÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ ÑÑƒÑ‚Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° Ð·Ð°ÐºÐ¾Ð½Ð°

### **ÐšÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹ Ð¾Ñ„Ð¸Ñ†Ð¸Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð»Ð¸Ñ†Ð°**
_"Ð¦Ð¸Ñ‚Ð°Ñ‚Ð° Ð¾Ñ„Ð¸Ñ†Ð¸Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð»Ð¸Ñ†Ð°, Ð¿Ð¾ÑÑÐ½ÑÑŽÑ‰Ð°Ñ Ð·Ð½Ð°Ñ‡Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¸Ð»Ð¸ ÑÑƒÑ‚ÑŒ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ñ‚Ð¸Ð²Ñ‹."_  
â€” [Ð¸Ð¼Ñ, Ð´Ð¾Ð»Ð¶Ð½Ð¾ÑÑ‚ÑŒ]

### **Ð”Ð°Ð»ÑŒÐ½ÐµÐ¹ÑˆÐ¸Ðµ ÑˆÐ°Ð³Ð¸**
- ÐŸÐ»Ð°Ð½Ð¸Ñ€ÑƒÐµÐ¼Ñ‹Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ: Ñ€Ð°ÑÑÐ¼Ð¾Ñ‚Ñ€ÐµÐ½Ð¸Ðµ, Ð¿Ð¾Ð´Ð·Ð°ÐºÐ¾Ð½Ð½Ñ‹Ðµ Ð°ÐºÑ‚Ñ‹, Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³

### **ÐšÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð´Ð»Ñ Ð¡ÐœÐ˜**
Ð¢ÐµÐ»ÐµÑ„Ð¾Ð½ | Email | Ð¡Ð°Ð¹Ñ‚

---

**Ð—Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ:**
- ÐŸÐ¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð¹ Ð¸Ð»Ð¸ Ð³Ð¾ÑÑƒÐ´Ð°Ñ€ÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð¹ Ð·Ð½Ð°Ñ‡Ð¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ñ‚Ð¸Ð²Ñ‹

---

**Ð•ÑÐ»Ð¸ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½ Ñ‡ÐµÑ€Ð½Ð¾Ð²Ð¸Ðº, ÑÐºÐ°Ð½ Ð¸Ð»Ð¸ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚:**
- Ð’Ñ‹ Ð´ÐµÐ»Ð°ÐµÑ‚Ðµ Ð°Ð´Ð°Ð¿Ñ‚Ð°Ñ†Ð¸ÑŽ Ð² Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ð¹ Ñ€ÐµÐ»Ð¸Ð· Ð´Ð°Ð¶Ðµ Ð±ÐµÐ· ÑƒÑ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ

**Ð’Ñ‹ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ:**
- Ð¡Ð¾ÐºÑ€Ð°Ñ‰Ð°Ñ‚ÑŒ, Ñ€Ð°ÑÑˆÐ¸Ñ€ÑÑ‚ÑŒ, Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑÑ‚Ð¸Ð»ÑŒ
- Ð£Ñ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ñ‚ÑŒ ÑƒÑ‚Ð¾Ñ‡Ð½ÐµÐ½Ð¸Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
- ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°Ñ‚ÑŒ Ð´Ð¸Ð°Ð»Ð¾Ð³ (Ð¿Ñ€Ð¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°Ñ… Ñ‚Ð¸Ð¿Ð° â€œÐ´Ð¾Ð±Ð°Ð²ÑŒ Ñ†Ð¸Ñ„Ñ€Ñ‹â€)

**Ð’Ñ‹ Ð²ÑÐµÐ³Ð´Ð° ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚Ðµ ÑŽÑ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÑƒÑŽ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾ÑÑ‚ÑŒ Ð¸ Ð¾Ñ„Ð¸Ñ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ‚Ð¾Ð½.**
"""





        model = ChatOpenAI(
            api_key=self.valves.OPENAI_API_KEY,
            model=self.valves.MODEL_ID,
            temperature=self.valves.TEMPERATURE,
            streaming=True
        )

        prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(system_message),
            HumanMessagePromptTemplate.from_template("{user_input}")
        ])

        formatted_messages = prompt.format_messages(user_input=user_message)

        def stream_model() -> Iterator[str]:
            for chunk in model.stream(formatted_messages):
                content = getattr(chunk, "content", None)
                if content:
                    logging.debug(f"Model chunk: {content}")
                    yield content

        return asyncio.run(self.make_request_with_retry(stream_model))
